{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importa for data visualization\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read sfdata (NO NEED TO RUN!)\n",
    "sfdata_file = \"../data/sf.csv\"\n",
    "sfdata = pd.read_csv(sfdata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Warnings raised:', [<warnings.WarningMessage object at 0x7f9659226550>])\n",
      "('Warning message:', 'Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.')\n",
      "(\"Applying <type 'str'> dtype to columns:\", [10])\n"
     ]
    }
   ],
   "source": [
    "# Read bosdata\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "bos_file = '../data/boston.csv'\n",
    "target_type = str  # The desired output type\n",
    "\n",
    "with warnings.catch_warnings(record=True) as ws:\n",
    "    warnings.simplefilter(\"always\")\n",
    "\n",
    "    bosData = pd.read_csv(bos_file, sep=\",\", header=0)\n",
    "    print(\"Warnings raised:\", ws)\n",
    "    # We have an error on specific columns, try and load them as string\n",
    "    for w in ws:\n",
    "        s = str(w.message)\n",
    "        print(\"Warning message:\", s)\n",
    "        match = re.search(r\"Columns \\(([0-9,]+)\\) have mixed types\\.\", s)\n",
    "        if match:\n",
    "            columns = match.group(1).split(',') # Get columns as a list\n",
    "            columns = [int(c) for c in columns]\n",
    "            print(\"Applying %s dtype to columns:\" % target_type, columns)\n",
    "            bosData.iloc[:,columns] = bosData.iloc[:,columns].astype(target_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a crime-count column to quickly count the data\n",
    "bosData['CrimeCount'] = 1\n",
    "sfdata['CrimeCount'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotCrimeCounts(data, features, city):\n",
    "    '''\n",
    "    Data is the dataframe containing the crime statistics.\n",
    "    Features is  disctionary mapping {description: column}\n",
    "    city is the name of the city for which we are plotting.\n",
    "    '''\n",
    "    for description, columnName in features.iteritems():\n",
    "        sns.countplot(y=columnName, data=data)\n",
    "        plt.title('Crimes in {} by {}'.format(city, description))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create histograms on some important metrics\n",
    "# Map from english_description : column name\n",
    "columnsToPlotSF = { 'Police District' : 'PdDistrict',\n",
    "                    'Crime Type' : 'Category',\n",
    "                    'Day of the Week' : 'DayOfWeek',\n",
    "                   'Crime Outcome' : 'Resolution' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotCrimeCounts(sfdata, columnsToPlotSF, 'San Francisco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create histograms on some important metrics for Boston\n",
    "columnsToPlotBos = { 'Reporting District' : 'REPTDISTRICT', \n",
    "                     'Weapon Type' : 'WEAPONTYPE',\n",
    "                     'Shooting/No Shooting' : 'Shooting',\n",
    "                     'Officer Shift' : 'SHIFT',\n",
    "                     'Year' : 'Year', \n",
    "                     'Month' : 'Month',\n",
    "                     'Day of the Week' : 'DAY_WEEK'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotCrimeCounts(bosData, columnsToPlotBos, 'Boston')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadPickle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert date to actual date format. This might take a while!\n",
    "# Note that we should not have to do this once the data\n",
    "# has been cleaned!\n",
    "# SKIP IF CLEAN DATA EXISTS\n",
    "if not loadPickle:\n",
    "    sfdata.Date = sfdata['Date'].apply(lambda x: pd.to_datetime(x, errors='raise'))\n",
    "    sfdata.Time = sfdata['Time'].apply(lambda x: pd.to_datetime(x, errors='raise'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions to help clean SF data. We do this only once, as we \n",
    "# now save the results using pickle!\n",
    "def buckets(series, n):\n",
    "    # Takes a series and returns a series mapping each element to a\n",
    "    # one of n buckets.\n",
    "    mi, ma = series.min(), series.max()\n",
    "    buckets = np.linspace(mi, ma, n)\n",
    "    # print buckets\n",
    "    def f(e):\n",
    "        for i, el in enumerate(buckets):\n",
    "            if e < el:\n",
    "                return i\n",
    "        return n - 1\n",
    "            \n",
    "    res = series.map(f)\n",
    "    return res\n",
    "\n",
    "def cleanColumns(data):\n",
    "    # Used to rename the columns in our data grame to their appropriate names.\n",
    "    # Also drops unnecessary columns.\n",
    "    data['Latitude'] = data['Y']\n",
    "    data['Longitude'] = data['X']\n",
    "    data['Type'] = data['Category']\n",
    "    \n",
    "    # print data.columns\n",
    "    data = data.drop(['IncidntNum', 'Descript','Resolution','Address','X','Y', 'Location'], axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def createPartitions(data, n):\n",
    "    # Remove outliers from the latitude/longitude issues\n",
    "    # We know that the city lies between -130, -120 longitude\n",
    "    # We also know that the citiy lies between 37 and 40 degrees latitude\n",
    "    data = data[-120 > data.Longitude][data.Longitude > (-130)]\n",
    "    data = data[data.Latitude > 37][data.Latitude < 40]\n",
    "    \n",
    "    # Each row is an occurrance of a single crime. \n",
    "    # Keep around the original data\n",
    "    data['Region'] =  n *  buckets(data['Latitude'], n) + buckets(data['Longitude'],n) + 1\n",
    "    data['xRegion'] = buckets(data['Latitude'], n)\n",
    "    data['yRegion'] =  buckets(data['Longitude'],n) + 1\n",
    "    data['Region'] =  n * data.yRegion + data.xRegion    \n",
    "    \n",
    "    # Add in the types into the results.\n",
    "    mapping = {key: i for i,key in enumerate(data['Type'].unique())}\n",
    "    data['TypeIndex'] = data['Type'].map(mapping)\n",
    "\n",
    "    # Now we can add the crime counts. \n",
    "    data['CrimeCount'] = np.ones(len(data))\n",
    "    return data\n",
    "\n",
    "def extractDateFeatures(data):\n",
    "    # Creates a new data frame and returns it as copy with all the data that we're interested in\n",
    "    # Create map from week days to integers\n",
    "    DayOfWeek = {'Sunday': 1,\n",
    "                 'Monday': 2,\n",
    "                 'Tuesday': 3,\n",
    "                 'Wednesday': 4,\n",
    "                 'Thursday': 5,\n",
    "                 'Friday': 6,\n",
    "                 'Saturday': 7 }\n",
    "    data['DoW'] = data['DayOfWeek'].map(DayOfWeek)\n",
    "    data = data.drop('DayOfWeek', axis=1)\n",
    "    print \"Created Weeks\"\n",
    "    \n",
    "    # We assume that the Date column is already in datetime format\n",
    "    data['Month'] = data.Date.map(lambda x: x.month)\n",
    "    data['DoM'] = data.Date.map(lambda x: x.day)\n",
    "    data['Year'] = data.Date.map(lambda x: x.year) - data.Date.min().year\n",
    "    data['ToD'] = data.Time.map(lambda x: x.minute)\n",
    "    data['Time'] = data.Time.map(lambda x: x.value / 10**9) - data.Date.min().value / 10**9\n",
    "    \n",
    "    # We add an additional column that combines the month and the year into number of months since beginning\n",
    "    data['TimeFeature'] = data.ix[:, ['Year', 'Month']].apply(lambda s: 12*s[0] + s[1], axis=1)\n",
    "    \n",
    "    data = data.drop('Date', axis=1)\n",
    "    \n",
    "    print \"Created the time data features!\"\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfpickle_file = '../../cs281_data/large_data/sfclean.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We only need to do this once, afterwards we should load from the \n",
    "# saved location.\n",
    "# DO NOT RUN IF PICKLED FILE ALREADY EXISTS\n",
    "if not loadPickle:\n",
    "    sfclean = cleanColumns(sfdata)\n",
    "    sfclean = extractDateFeatures(sfclean)\n",
    "    sfclean.to_pickle(sfpickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load sfclean from pickled location!\n",
    "import pickle\n",
    "sfclean = open(sfpickle_file)\n",
    "sfclean = pickle.load(sfclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort the data by time\n",
    "sfclean = sfclean.sort_values(by='TimeFeature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save memory by deleting old data\n",
    "# del(sfdata)\n",
    "# del(sfclean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate some additional histograms\n",
    "columnsToPlotSF2 = { 'Month' : 'Month',\n",
    "                    'Day of Month' : 'DoM',\n",
    "                    'Year' : 'Year',\n",
    "                   'Hour of Day' : 'ToD' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotCrimeCounts(sfclean, columnsToPlotSF2, 'Boston')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make histograms of the crimes by month for each given year\n",
    "years = bosData.Year.unique()\n",
    "for year in years:\n",
    "    # Subset the data\n",
    "    data = bosData[bosData.Year == year]\n",
    "    \n",
    "    # Make a histogram based on month\n",
    "    sns.countplot(x = 'Month', data=data)\n",
    "    plt.title('Boston Crime Histogram for {}'.format(year))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat the above procedure but do it for the sf data\n",
    "years = sfclean.Year.unique()\n",
    "for year in years:\n",
    "    data = sfclean[sfclean.Year == year]\n",
    "    \n",
    "    sns.countplot(x = 'Month', data=data)\n",
    "    plt.title('San Francisco Crime Histogram for {}'.format(2001 + year))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's generate some heatmaps for both of these data crimes\n",
    "# Can we overlay these on top of the geographical location???\n",
    "n = 30\n",
    "partitionedData = createPartitions(sfclean, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's do one really large heatmap\n",
    "def createHeatmapData(data):\n",
    "    # data is what we're making a heatmap on.\n",
    "    # Using the San Francisco data set, we create an nxn matrix\n",
    "    # which counts the number of crimes in a given area!\n",
    "    res = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            res[i,j] = len(data[(data.xRegion == i) & (data.yRegion == j)])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(createHeatmapData(partitionedData))\n",
    "plt.title('Crime Distribution in San Francisco')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's redo the heatmap year by year?\n",
    "years = partitionedData.Year.unique()\n",
    "for year in years:\n",
    "    data = partitionedData[partitionedData.Year == year]\n",
    "    \n",
    "    sns.heatmap(createHeatmapData(data))\n",
    "    plt.title('Crime Distribution in San Francisco for {}'.format(year + 2001))\n",
    "    plt.savefig('../figures/sf_data_analysis/heat_map_{}'.format(year + 2001))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's redo it month by month because that's what we want to analyze?\n",
    "years = partitionedData.Year.unique()\n",
    "months = partitionedData.Month.unique()\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        data = partitionedData[(partitionedData.Year == year) &\n",
    "                               (partitionedData.Month == month)]\n",
    "        sns.heatmap(createHeatmapData(data))\n",
    "        plt.title('Crime Distribution in San Francisco for {}, {}'.format(month, year + 2001))\n",
    "        plt.savefig('../figures/sf_data_analysis/heat_map_{}_{}'.format(month, year+2001))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "steps = {}\n",
    "def operationsToK(numbers, k, epsilon = 0.0001):\n",
    "    try:\n",
    "        return res[tuple(numbers),k]\n",
    "    except KeyError:\n",
    "        if len(numbers) == 1:\n",
    "            return abs(numbers[0] - k) < epsilon\n",
    "        for number in numbers:\n",
    "            newSet = list(numbers)\n",
    "            newSet.remove(number)\n",
    "            # print newSet\n",
    "            if operationsToK(newSet, k - number):\n",
    "                res[tuple(numbers), k] = True\n",
    "                steps[tuple(numbers), k] = '{}-{}'.format(k,number)\n",
    "                return True\n",
    "            if operationsToK(newSet, number- k):\n",
    "                res[tuple(numbers), k] = True\n",
    "                steps[tuple(numbers), k] = '{}-{}'.format(number,k)\n",
    "                return True\n",
    "            if operationsToK(newSet, number+ k):\n",
    "                res[tuple(numbers), k] = True\n",
    "                steps[tuple(numbers), k] = '{}+{}'.format(k,number)\n",
    "                return True\n",
    "            if operationsToK(newSet, number * k):\n",
    "                res[tuple(numbers), k] = True\n",
    "                steps[tuple(numbers), k] = '{}*{}'.format(k,number)\n",
    "                return True\n",
    "            if operationsToK(newSet, float(number) / k):\n",
    "                res[tuple(numbers), k] = True\n",
    "                steps[tuple(numbers), k] = '{}/{}'.format(number,k)\n",
    "                return True\n",
    "            if operationsToK(newSet, k / float(number)):\n",
    "                res[tuple(numbers), k] = True\n",
    "                steps[tuple(numbers), k] = '{}/{}'.format(k,number)\n",
    "                return True\n",
    "        res[tuple(numbers), k] = False\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "steps = {}\n",
    "print operationsToK([1,5,5,5], 0.20000000000000018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{((1, 5, 5, 5), 0.20000000000000018): '0.2*1',\n",
       " ((5, 5), 1.0000000000000009): '1.0*5',\n",
       " ((5, 5, 5), 0.20000000000000018): '0.2*5'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls = [1,1]\n",
    "ls.remove(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
