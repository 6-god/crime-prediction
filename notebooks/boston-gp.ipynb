{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sklearn.linear_model as lm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Utility Functions\n",
    "'''\n",
    "# DATA: months since 2012, X coord, Y coord\n",
    "def split(X, tr_size):\n",
    "    Y = np.copy(X)\n",
    "    np.random.shuffle(Y)\n",
    "    break_pt = tr_size * np.shape(Y)[0]\n",
    "    return Y[:break_pt,:], Y[break_pt:,:]\n",
    "\n",
    "# implementation notes: set NaN to mean\n",
    "def normalize_features(X_train):\n",
    "    mean_X_train = np.nanmean(X_train, 0)\n",
    "    for i in xrange(np.shape(X_train)[1]):\n",
    "        col = X_train[:,i]\n",
    "        col[ np.isnan(col) ] = mean_X_train[i]\n",
    "    std_X_train = np.std(X_train, 0)\n",
    "    std_X_train[ std_X_train == 0 ] = 1\n",
    "    X_train_normalized = (X_train - mean_X_train) / std_X_train\n",
    "    return X_train_normalized\n",
    "\n",
    "# Note: bucket edits in place\n",
    "def bucket(X, cols, num_buckets):\n",
    "    Y = np.copy(X)\n",
    "    for col in cols:\n",
    "        buckets = np.linspace(np.min(X[:,col]), np.max(X[:,col]), num=num_buckets+1)\n",
    "        for i in xrange(num_buckets):\n",
    "            X_col = Y[:,col]\n",
    "            X_col[ (buckets[i] <= X_col) & (X_col <= buckets[i+1])] = i\n",
    "            Y[:,col] = X_col\n",
    "    return Y\n",
    "\n",
    "def rmse(predict, true):\n",
    "    return np.sqrt(1.0/np.shape(predict)[0] * np.sum(np.square(predict - true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Warnings raised:', [<warnings.WarningMessage object at 0x7fcc49408a50>])\n",
      "('Warning message:', 'Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.')\n",
      "(\"Applying <type 'str'> dtype to columns:\", [10])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Read in data\n",
    "'''\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "bos_file = '../data/boston.csv'\n",
    "target_type = str  # The desired output type\n",
    "\n",
    "with warnings.catch_warnings(record=True) as ws:\n",
    "    warnings.simplefilter(\"always\")\n",
    "\n",
    "    bos_data = pd.read_csv(bos_file, sep=\",\", header=0)\n",
    "    print(\"Warnings raised:\", ws)\n",
    "    # We have an error on specific columns, try and load them as string\n",
    "    for w in ws:\n",
    "        s = str(w.message)\n",
    "        print(\"Warning message:\", s)\n",
    "        match = re.search(r\"Columns \\(([0-9,]+)\\) have mixed types\\.\", s)\n",
    "        if match:\n",
    "            columns = match.group(1).split(',') # Get columns as a list\n",
    "            columns = [int(c) for c in columns]\n",
    "            print(\"Applying %s dtype to columns:\" % target_type, columns)\n",
    "            bos_data.iloc[:,columns] = bos_data.iloc[:,columns].astype(target_type)\n",
    "\n",
    "'''\n",
    "Featurize data\n",
    "'''\n",
    "# temporal features\n",
    "# day of week\n",
    "day = np.array(bos_data.DAY_WEEK)\n",
    "day[ day == \"Sunday\"] = 0\n",
    "day[ day == \"Monday\"] = 1\n",
    "day[ day == \"Tuesday\"] = 2\n",
    "day[ day == \"Wednesday\"] = 3\n",
    "day[ day == \"Thursday\"] = 4\n",
    "day[ day == \"Friday\"] = 5\n",
    "day[ day == \"Saturday\"] = 6\n",
    "\n",
    "date_time = np.array([x.split() for x in bos_data.FROMDATE])\n",
    "date = date_time[:,0]\n",
    "time = date_time[:,1]\n",
    "tod = date_time[:,2]\n",
    "\n",
    "# month, day, year\n",
    "date = np.array([x.split('/') for x in date])\n",
    "month = [int(x) for x in date[:,0]]\n",
    "dom = [int(x) for x in date[:,1]]\n",
    "year = [int(x) for x in date[:,2]]\n",
    "time_feat = np.subtract(year, 2012)*12 + month\n",
    "\n",
    "# time of day\n",
    "time_c = [x.split(':') for x in time]\n",
    "time = [int(x[1]) if (y == 'AM' and int(x[0]) == 12) else 60*int(x[0])+int(x[1]) \n",
    "        if (y =='AM' and int(x[0]) != 12) or (int(x[0]) == 12 and y == 'PM') else 12*60+60*int(x[0])+int(x[1]) \n",
    "        for x,y in zip(time_c, tod)]\n",
    "\n",
    "data_unnorm = np.transpose(np.vstack((time_feat, bos_data.X, bos_data.Y))).astype(float)\n",
    "# remove NaNs\n",
    "good_data = data_unnorm[~(np.isnan(data_unnorm[:,1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Count data for each cell\n",
    "'''\n",
    "n_buckets = 15 # 5\n",
    "data_b = bucket(good_data, [1, 2], n_buckets)\n",
    "\n",
    "years = [2012, 2013, 2014, 2015]\n",
    "n_time = int(data_b[np.argmax(data_b[:,0])][0])\n",
    "\n",
    "buckets = np.zeros((n_time, n_buckets, n_buckets))\n",
    "buckets2 = np.zeros((n_buckets * n_buckets * n_time, 4))\n",
    "\n",
    "# divide the data up by year and month\n",
    "for i in xrange(n_time):\n",
    "    for j in xrange(n_buckets):\n",
    "        for k in xrange(n_buckets):\n",
    "            count = data_b[ (data_b[:,0] == i+1) & \n",
    "                            (data_b[:,1] == j) & \n",
    "                            (data_b[:,2] == k)]\n",
    "            buckets[i][j][k] = np.size(count,0)\n",
    "            buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][0] = i\n",
    "            buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][1] = j\n",
    "            buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][2] = k\n",
    "            buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][3] = np.size(count,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9900, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(buckets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Split into test and train, r for random\n",
    "'''\n",
    "train_r, test_r = split(buckets2, .8)\n",
    "train_rt = train_r[:,[3]]\n",
    "train_r = train_r[:,[0,1,2]]\n",
    "test_rt = test_r[:,[3]]\n",
    "test_r = test_r[:,[0,1,2]]\n",
    "\n",
    "'''\n",
    "Holdout most recent year\n",
    "'''\n",
    "\n",
    "# 875 for 5 buckets; 3500 for 10 buckets\n",
    "train, test = buckets2[:7875,:], buckets2[7875:,:]\n",
    "train_t = train[:,[3]]\n",
    "train = train[:,[0,1,2]]\n",
    "test_t = test[:,[3]]\n",
    "test = test[:,[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Our GP\n",
    "    other implementations:\n",
    "    - scikit-learn\n",
    "    - GPy\n",
    "'''\n",
    "\n",
    "\n",
    "sig_eps = 1.0\n",
    "\n",
    "# compute the kernel matrix\n",
    "# use square exponential by default\n",
    "def ker_se(x, y, l, horz=1.0, vert = 1.0):\n",
    "    \n",
    "    n = np.shape(x)[0]\n",
    "    m = np.shape(y)[0]\n",
    "    \n",
    "    t = np.reshape(x, (np.shape(x)[0], 1, np.shape(x)[1]))\n",
    "    s = np.reshape(y, (1, np.shape(y)[0], np.shape(y)[1]))\n",
    "\n",
    "    # tile across columns\n",
    "    cols = np.tile(t, (1, m, 1))\n",
    "    # tile across rows\n",
    "    rows = np.tile(s, (n, 1, 1))\n",
    "    # get the differences and vectorize\n",
    "    diff_vec = np.reshape(cols - rows, (n*m, np.shape(t)[2]))\n",
    "    \n",
    "    M = np.diag(l)\n",
    "    \n",
    "    # use multiply and sum to calculate matrix product\n",
    "    s = np.multiply(-.5, np.sum(np.multiply(diff_vec, np.transpose(np.dot(M, np.transpose(diff_vec)))), axis=1))\n",
    "    se = np.reshape(np.multiply(horz, np.exp(s)), (n, m))\n",
    "    \n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate kernels\n",
    "'''\n",
    "\n",
    "l = np.ones(3)\n",
    "ker1 = ker_se(train, train, l)\n",
    "ker2 = ker_se(test, test, l)\n",
    "ker3 = ker_se(train,test, l)\n",
    "\n",
    "'''\n",
    "GP regression\n",
    "'''\n",
    "\n",
    "L = np.linalg.cholesky(ker1 + np.multiply(sig_eps, np.identity(np.shape(ker1)[0]))) # need to add noise\n",
    "alpha = np.linalg.solve(L.T, np.linalg.solve(L, train_t))\n",
    "preds = np.dot(np.transpose(ker3), alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "RMSE\n",
    "'''\n",
    "print np.sqrt(np.sum(np.square(preds - test_t))/np.shape(preds)[0])\n",
    "\n",
    "'''\n",
    "Marginal likelihood: -.5 y * alpha - sum_i L_ii - N/2 log(2pi)\n",
    "'''\n",
    "print -.5 * np.dot(np.transpose(train_t), alpha) - np.sum(np.log(np.diagonal(L))) - np.shape(ker1)[0]/2 * np.log(2*np.pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
