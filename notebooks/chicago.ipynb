{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import sklearn.linear_model as lm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Utility functions\n",
    "'''\n",
    "def split(X, split_size):\n",
    "    np.random.shuffle(X)\n",
    "    break_pt = split_size * np.shape(X)[0]\n",
    "    return X[:break_pt,:], X[break_pt:,:]\n",
    "\n",
    "# implementation notes: set NaN to mean\n",
    "def normalize_features(X_train):\n",
    "    mean_X_train = np.nanmean(X_train, 0)\n",
    "    for i in xrange(np.shape(X_train)[1]):\n",
    "        col = X_train[:,i]\n",
    "        col[ np.isnan(col) ] = mean_X_train[i]\n",
    "    std_X_train = np.std(X_train, 0)\n",
    "    std_X_train[ std_X_train == 0 ] = 1\n",
    "    X_train_normalized = (X_train - mean_X_train) / std_X_train\n",
    "    return X_train_normalized\n",
    "\n",
    "# Note: bucket edits in place\n",
    "def bucket(X, cols, num_buckets):\n",
    "    Y = np.copy(X)\n",
    "    for col in cols:\n",
    "        buckets = np.linspace(np.min(X[:,col]), np.max(X[:,col]), num=num_buckets+1)\n",
    "        for i in xrange(num_buckets):\n",
    "            X_col = Y[:,col]\n",
    "            X_col[ (buckets[i] <= X_col) & (X_col <= buckets[i+1])] = i\n",
    "            Y[:,col] = X_col\n",
    "    return Y\n",
    "\n",
    "def rmse(predict, true):\n",
    "    return np.sqrt(1.0/np.shape(predict)[0] * np.sum(np.square(predict - true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Warnings raised:', [])\n",
      "finished 2001.0\n",
      "('Warnings raised:', [])\n",
      "finished 2002.0\n",
      "('Warnings raised:', [])\n",
      "finished 2003.0\n",
      "('Warnings raised:', [])\n",
      "finished 2004.0\n",
      "('Warnings raised:', [])\n",
      "finished 2005.0\n",
      "('Warnings raised:', [])\n",
      "finished 2006.0\n",
      "('Warnings raised:', [])\n",
      "finished 2007.0\n",
      "('Warnings raised:', [])\n",
      "finished 2008.0\n",
      "('Warnings raised:', [])\n",
      "finished 2009.0\n",
      "('Warnings raised:', [])\n",
      "finished 2010.0\n",
      "('Warnings raised:', [])\n",
      "finished 2011.0\n",
      "('Warnings raised:', [])\n",
      "finished 2012.0\n",
      "('Warnings raised:', [])\n",
      "finished 2013.0\n",
      "('Warnings raised:', [])\n",
      "finished 2014.0\n",
      "('Warnings raised:', [])\n",
      "finished 2015.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load in data\n",
    "'''\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "years = 2000 + np.linspace(1,15, 15)\n",
    "buckets = np.zeros(1)\n",
    "target_type = str  # The desired output type\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    data_file = '../data/Crimes_-_%d.csv' % year\n",
    "\n",
    "    with warnings.catch_warnings(record=True) as ws:\n",
    "        warnings.simplefilter(\"always\")\n",
    "\n",
    "        data = pd.read_csv(data_file, sep=\",\", header=0)\n",
    "        print(\"Warnings raised:\", ws)\n",
    "        # We have an error on specific columns, try and load them as string\n",
    "        for w in ws:\n",
    "            s = str(w.message)\n",
    "            print(\"Warning message:\", s)\n",
    "            match = re.search(r\"Columns \\(([0-9,]+)\\) have mixed types\\.\", s)\n",
    "            if match:\n",
    "                columns = match.group(1).split(',') # Get columns as a list\n",
    "                columns = [int(c) for c in columns]\n",
    "                print(\"Applying %s dtype to columns:\" % target_type, columns)\n",
    "                data.iloc[:,columns] = data.iloc[:,columns].astype(target_type)\n",
    "\n",
    "    '''\n",
    "    Extract Relevant Features\n",
    "    '''\n",
    "    # temporal features\n",
    "    date_time = np.array([x.split() for x in data.Date])\n",
    "    date = date_time[:,0]\n",
    "    time = date_time[:,1]\n",
    "    tod = date_time[:,2]\n",
    "\n",
    "    # month, day, year\n",
    "    date = np.array([x.split('/') for x in date])\n",
    "    month = [int(x) for x in date[:,0]]\n",
    "    dom = [int(x) for x in date[:,1]]\n",
    "    years = [int(x) for x in date[:,2]]\n",
    "    time_feat = np.subtract(years, 2001)*12 + month\n",
    "\n",
    "    # time of day\n",
    "    time_c = [x.split(':') for x in time]\n",
    "    time = [int(x[1]) if (y == 'AM' and int(x[0]) == 12) else 60*int(x[0])+int(x[1]) \n",
    "            if (y =='AM' and int(x[0]) != 12) or (int(x[0]) == 12 and y == 'PM') else 12*60+60*int(x[0])+int(x[1]) \n",
    "            for x,y in zip(time_c, tod)]\n",
    "\n",
    "    feats = np.transpose(np.vstack((time_feat, data.Latitude, data.Longitude))).astype(float)\n",
    "\n",
    "    # remove NaNs\n",
    "    feats = feats[~(np.isnan(feats[:,1]))]\n",
    "\n",
    "    # bucket the data\n",
    "    n_buckets = 5\n",
    "    data_b = bucket(feats, [1, 2], n_buckets)\n",
    "    \n",
    "    n_time = 12 #int(data_b[np.argmax(data_b[:,0])][0])\n",
    "\n",
    "    #buckets = np.zeros((n_time, n_buckets, n_buckets))\n",
    "    buckets2 = np.zeros((n_buckets * n_buckets * n_time, 4))\n",
    "\n",
    "    # count the data per geographic cell per month\n",
    "    for i in xrange(n_time):\n",
    "        for j in xrange(n_buckets):\n",
    "            for k in xrange(n_buckets):\n",
    "\n",
    "                # note: one-indexing for months\n",
    "                mo = i+1+(year-2001)*12\n",
    "                count = data_b[ (data_b[:,0] == mo) & \n",
    "                                (data_b[:,1] == j) & \n",
    "                                (data_b[:,2] == k) ]\n",
    "    #            buckets[i][j][k] = np.size(count,0)\n",
    "                buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][0] = mo\n",
    "                buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][1] = j\n",
    "                buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][2] = k\n",
    "                buckets2[i*(n_buckets * n_buckets)+j*(n_buckets)+k][3] = np.size(count,0)\n",
    "    \n",
    "    if np.size(buckets) == 1:\n",
    "        buckets = buckets2\n",
    "    else:\n",
    "        buckets = np.vstack((buckets, buckets2))\n",
    "    \n",
    "    print \"finished\", year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"chicago_feats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(buckets, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
